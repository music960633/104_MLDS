train data: all
mu =  0.01
mu -= 0.00001
batch_size =  256
batch_num =  1024
3 layers: 69-256-256-48
start training
0  cost:  1.0233853425
1  cost:  0.984491508687
2  cost:  0.958407199185
3  cost:  0.947641996259
4  cost:  0.940718869271
5  cost:  0.939318940334
6  cost:  0.92425557744
7  cost:  0.914094976149
8  cost:  0.904896149179
9  cost:  0.898685901018
10  cost:  0.894331803254
11  cost:  0.891196670302
12  cost:  0.889328898047
13  cost:  0.888248851639
14  cost:  0.887294161075
15  cost:  0.884512434015
16  cost:  0.85868960619
17  cost:  0.836015623179
18  cost:  0.825489326264
19  cost:  0.822100681253
20  cost:  0.816509041935
